{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexica\n",
    "\n",
    "(Lexicon): a dictionary, a vocabulary of a language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import gutenberg as gut\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import cmudict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synsets('dog')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('cardigan.n.02')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hyponyms()[1].hyponyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('organism.n.01')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.hypernyms()[1].hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHypernyms(word): \n",
    "    return word.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " [Synset('canine.n.02'),\n",
       "  [Synset('carnivore.n.01'),\n",
       "   [Synset('placental.n.01'),\n",
       "    [Synset('mammal.n.01'),\n",
       "     [Synset('vertebrate.n.01'),\n",
       "      [Synset('chordate.n.01'),\n",
       "       [Synset('animal.n.01'),\n",
       "        [Synset('organism.n.01'),\n",
       "         [Synset('living_thing.n.01'),\n",
       "          [Synset('whole.n.02'),\n",
       "           [Synset('object.n.01'),\n",
       "            [Synset('physical_entity.n.01'),\n",
       "             [Synset('entity.n.01')]]]]]]]]]]]]],\n",
       " [Synset('domestic_animal.n.01'),\n",
       "  [Synset('animal.n.01'),\n",
       "   [Synset('organism.n.01'),\n",
       "    [Synset('living_thing.n.01'),\n",
       "     [Synset('whole.n.02'),\n",
       "      [Synset('object.n.01'),\n",
       "       [Synset('physical_entity.n.01'), [Synset('entity.n.01')]]]]]]]]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.tree(getHypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gut.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = gut.words('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34110"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.max_depth(), dog.min_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeWords(words):\n",
    "    \"\"\" \n",
    "    This function categorizes words by finding their hypernyms in WordNet. \n",
    "    \"\"\"\n",
    "    categoriesDict = {}\n",
    "    words = [word.lower() for word in words if word not in stops]\n",
    "    for word in words: \n",
    "        # Get synset\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) > 0: \n",
    "            synset = synsets[0]\n",
    "        else: \n",
    "            continue\n",
    "        # Get hypernym\n",
    "        depth = synset.min_depth()\n",
    "        hypernym = \"\"\n",
    "        while depth > 1:\n",
    "            hypernyms = synset.hypernyms()\n",
    "            if len(hypernyms) > 0: \n",
    "                hypernym = hypernyms[0]\n",
    "            else: \n",
    "                hypernym = \"\"\n",
    "            depth -= 1\n",
    "        # Count all the hypernyms\n",
    "        if hypernym in categoriesDict: \n",
    "            categoriesDict[hypernym] += 1\n",
    "        else: \n",
    "            categoriesDict[hypernym] = 1\n",
    "    return categoriesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliceCategories = categorizeWords(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            3287\n",
       "Synset('chemical_element.n.01')              597\n",
       "Synset('digit.n.01')                         209\n",
       "Synset('small_indefinite_quantity.n.01')     150\n",
       "Synset('kind.n.01')                          124\n",
       "Synset('rodent.n.01')                        100\n",
       "Synset('content.n.05')                        91\n",
       "Synset('knowing.n.01')                        90\n",
       "Synset('external_body_part.n.01')             87\n",
       "Synset('excavation.n.03')                     84\n",
       "Synset('leporid.n.01')                        83\n",
       "Synset('insect.n.01')                         75\n",
       "Synset('case.n.01')                           71\n",
       "Synset('body_part.n.01')                      71\n",
       "Synset('engineering.n.02')                    69\n",
       "Synset('activity.n.01')                       68\n",
       "Synset('seat.n.05')                           67\n",
       "Synset('property.n.02')                       65\n",
       "Synset('sovereign.n.01')                      64\n",
       "Synset('time_unit.n.01')                      62\n",
       "Synset('jersey.n.03')                         61\n",
       "Synset('rank.n.02')                           58\n",
       "Synset('shift.n.03')                          57\n",
       "Synset('maker.n.01')                          57\n",
       "Synset('person.n.01')                         56\n",
       "Synset('large_indefinite_quantity.n.01')      56\n",
       "Synset('derision.n.02')                       56\n",
       "Synset('opportunity.n.01')                    55\n",
       "Synset('act.n.02')                            55\n",
       "Synset('mythical_monster.n.01')               55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(aliceCategories).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('helium.n.01'), Synset('he.n.02')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('he')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation\n",
    "\n",
    "Lesk Algorithm: looks at surrounding words and compares their wordnet senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMUDict (Pronouncing Dictionary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmuDict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HH', 'AH0', 'L', 'OW1'], ['HH', 'EH0', 'L', 'OW1']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmuDict['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-64675ae60185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F-K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nix/store/ri16rfphbb502xa9iqyj1c0llpcfc6ca-python3-3.8.6-env/lib/python3.8/site-packages/nltk/text.py\u001b[0m in \u001b[0;36mreadability\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# code from nltk_contrib.readability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk.Text.readability('hello', method='F-K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonesthemes (Anglo-Saxon words) \n",
    "\n",
    "- -ash: bash, crash, dash, smash\n",
    "- gl-: glow, glimmer, glint, glisten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etymology\n",
    "\n",
    "kingly / royal / regal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro-etymology\n",
    "\n",
    "https://gist.github.com/JonathanReeve/25708b17dd172f9d5d6ba6f9d74a4ab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
